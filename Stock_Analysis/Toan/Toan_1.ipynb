{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still got stuck - terribly bad\n",
    "# Source: https://towardsdatascience.com/handling-missing-data-like-a-pro-part-1-deletion-methods-9f451b475429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#For data exploration\n",
    "import missingno as msno #A simple library to view completeness of data\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "# matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still dont know how to read data from file *.data and *.names to file *.txt or *.csv\n",
    "\n",
    "df = pd.read_csv('adult_data_Phi.txt')\n",
    "#df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Random Seed\n",
    "random.seed(25)\n",
    "\n",
    "#Percentage Missing\n",
    "percentage_missing_1 = 0.15\n",
    "percentage_missing_2 = 0.10\n",
    "\n",
    "#Number of Observations\n",
    "obs = df.shape[0]\n",
    "\n",
    "#Simulation\n",
    "df[\"fnlwgt\"] = random.binomial(1,(1-percentage_missing_1), size=obs)*df['fnlwgt']\n",
    "df[\"age\"] = random.binomial(1,(1-percentage_missing_2), size=obs)*df['age']\n",
    "df[\"fnlwgt\"] = df[\"fnlwgt\"].replace(0, np.nan)\n",
    "df[\"age\"]= df[\"age\"].replace(0, np.nan)\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df.copy()\n",
    "\n",
    "# importing the package\n",
    "import impyute as impy\n",
    "\n",
    "# imputing the missing value but ensure that the values are in matrix form\n",
    "df10[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']] = \\\n",
    "    impy.em(df10[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']].values, loops=100)\n",
    "\n",
    "df10\n",
    "\n",
    "# #Simulate New Comparison Container (So we can separate these new categories)\n",
    "# comparison_df = pd.concat([orig_df[['age', 'fnlwgt']], X], axis=1)\n",
    "\n",
    "# #Rename so We can Compare Across Datasets\n",
    "# comparison_df.columns = [\"age_orig\", \"fnlwgt_orig\", \"age_MCAR\", \"fnlwgt_MCAR\"]\n",
    "# cols = comparison_df.columns.to_list()\n",
    "# comparison_df = pd.concat([comparison_df, df10[['age', 'fnlwgt']]], axis=1)\n",
    "# comparison_df.columns =  [*cols,'age_EM.imp', 'fnlwgt_EM.imp']\n",
    "\n",
    "# #View the comparison across dataset\n",
    "# comparison_df.loc[fnlwgt_missing,[\"fnlwgt_orig\",\"fnlwgt_MCAR\",\n",
    "#                               'fnlwgt_EM.imp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df.copy()\n",
    "# imputing the missing value but ensure that the values are in matrix form\n",
    "df11[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']] = \\\n",
    "    np.exp(impy.em(np.log(df10[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']].values), loops=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is good and simple enough. Source: \n",
    "# https://joon3216.github.io/research_materials/2019/em_imputation_python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the values and transform values to z-scores\n",
    "# https://www.geeksforgeeks.org/scipy-stats-zscore-function-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>9.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     4    7     9  Unnamed: 4  9.1\n",
       "0            3   NaN  6.0   5.0         6.0  6.0\n",
       "1            3  10.0  NaN  10.0         5.0  NaN\n",
       "2            3   NaN  5.0   7.0         NaN  NaN\n",
       "3            5   5.0  7.0   NaN         7.0  5.0\n",
       "4            8   8.0  NaN   NaN         7.0  4.0\n",
       "5            5   NaN  8.0   5.0         6.0  5.0\n",
       "6            3   3.0  NaN   5.0         6.0  4.0\n",
       "7            7   7.0  NaN   4.0         7.0  8.0\n",
       "8            4   6.0  6.0   4.0         NaN  2.0\n",
       "9            7   NaN  8.0   5.0         7.0  6.0\n",
       "10           3   NaN  7.0   4.0         NaN  4.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from numpy import nan, array\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df\n",
    "df.info()\n",
    "\n",
    "# Also fails\n",
    "df2 = pd.read_csv('data2.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Z-score for df : \n",
      " [[-0.8977584          nan         nan         nan         nan         nan]\n",
      " [-0.8977584          nan         nan         nan         nan         nan]\n",
      " [-0.8977584          nan         nan         nan         nan         nan]\n",
      " [ 0.19950187         nan         nan         nan         nan         nan]\n",
      " [ 1.84539227         nan         nan         nan         nan         nan]\n",
      " [ 0.19950187         nan         nan         nan         nan         nan]\n",
      " [-0.8977584          nan         nan         nan         nan         nan]\n",
      " [ 1.29676214         nan         nan         nan         nan         nan]\n",
      " [-0.34912827         nan         nan         nan         nan         nan]\n",
      " [ 1.29676214         nan         nan         nan         nan         nan]\n",
      " [-0.8977584          nan         nan         nan         nan         nan]]\n"
     ]
    }
   ],
   "source": [
    "# stats.zscore() method  \n",
    "print (\"\\nZ-score for df : \\n\", stats.zscore(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mean and covariance matrix\n",
    "# Implement the Expectation - Maximization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_em(X, max_iter = 3000, eps = 1e-08):\n",
    "    '''(np.array, int, number) -> {str: np.array or int}\n",
    "    \n",
    "    Precondition: max_iter >= 1 and eps > 0\n",
    "    \n",
    "    Return the dictionary with five keys where:\n",
    "    - Key 'mu' stores the mean estimate of the imputed data.\n",
    "    - Key 'Sigma' stores the variance estimate of the imputed data.\n",
    "    - Key 'X_imputed' stores the imputed data that is mutated from X using \n",
    "      the EM algorithm.\n",
    "    - Key 'C' stores the np.array that specifies the original missing entries\n",
    "      of X.\n",
    "    - Key 'iteration' stores the number of iteration used to compute\n",
    "      'X_imputed' based on max_iter and eps specified.\n",
    "    '''\n",
    "    \n",
    "    nr, nc = X.shape\n",
    "    C = np.isnan(X) == False\n",
    "    \n",
    "    # Collect M_i and O_i's\n",
    "    one_to_nc = np.arange(1, nc + 1, step = 1)\n",
    "    M = one_to_nc * (C == False) - 1\n",
    "    O = one_to_nc * C - 1\n",
    "    \n",
    "    # Generate Mu_0 and Sigma_0\n",
    "    Mu = np.nanmean(X, axis = 0)\n",
    "    observed_rows = np.where(np.isnan(sum(X.T)) == False)[0]\n",
    "    S = np.cov(X[observed_rows, ].T)\n",
    "    if np.isnan(S).any():\n",
    "        S = np.diag(np.nanvar(X, axis = 0))\n",
    "    \n",
    "    # Start updating\n",
    "    Mu_tilde, S_tilde = {}, {}\n",
    "    X_tilde = X.copy()\n",
    "    no_conv = True\n",
    "    iteration = 0\n",
    "    while no_conv and iteration < max_iter:\n",
    "        for i in range(nr):\n",
    "            S_tilde[i] = np.zeros(nc ** 2).reshape(nc, nc)\n",
    "            if set(O[i, ]) != set(one_to_nc - 1): # missing component exists\n",
    "                M_i, O_i = M[i, ][M[i, ] != -1], O[i, ][O[i, ] != -1]\n",
    "                S_MM = S[np.ix_(M_i, M_i)]\n",
    "                S_MO = S[np.ix_(M_i, O_i)]\n",
    "                S_OM = S_MO.T\n",
    "                S_OO = S[np.ix_(O_i, O_i)]\n",
    "                Mu_tilde[i] = Mu[np.ix_(M_i)] +\\\n",
    "                    S_MO @ np.linalg.inv(S_OO) @\\\n",
    "                    (X_tilde[i, O_i] - Mu[np.ix_(O_i)])\n",
    "                X_tilde[i, M_i] = Mu_tilde[i]\n",
    "                S_MM_O = S_MM - S_MO @ np.linalg.inv(S_OO) @ S_OM\n",
    "                S_tilde[i][np.ix_(M_i, M_i)] = S_MM_O\n",
    "        Mu_new = np.mean(X_tilde, axis = 0)\n",
    "        S_new = np.cov(X_tilde.T, bias = 1) +\\\n",
    "            reduce(np.add, S_tilde.values()) / nr\n",
    "        no_conv =\\\n",
    "            np.linalg.norm(Mu - Mu_new) >= eps or\\\n",
    "            np.linalg.norm(S - S_new, ord = 2) >= eps\n",
    "        Mu = Mu_new\n",
    "        S = S_new\n",
    "        iteration += 1\n",
    "    \n",
    "    result = {\n",
    "        'mu': Mu,\n",
    "        'Sigma': S,\n",
    "        'X_imputed': X_tilde,\n",
    "        'C': C,\n",
    "        'iteration': iteration\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan, -0.85597905, -0.85597905, -0.85597905,  0.19021757,\n",
       "         1.75951249,  0.19021757, -0.85597905,  1.23641418, -0.33288074,\n",
       "         1.23641418, -0.85597905],\n",
       "       [-0.88904338,         nan,  1.60027808,         nan, -0.47415647,\n",
       "         0.77050426,         nan, -1.30393029,  0.35561735, -0.05926956,\n",
       "                nan,         nan],\n",
       "       [ 0.24152295, -0.72456884,         nan, -1.69066062,  0.24152295,\n",
       "                nan,  1.20761473,         nan,         nan, -0.72456884,\n",
       "         1.20761473,  0.24152295],\n",
       "       [ 1.48841682, -0.3721042 ,  1.95354707,  0.55815631,         nan,\n",
       "                nan, -0.3721042 , -0.3721042 , -0.83723446, -0.83723446,\n",
       "        -0.3721042 , -0.83723446],\n",
       "       [        nan, -0.50401613, -1.84805914,         nan,  0.84002688,\n",
       "         0.84002688, -0.50401613, -0.50401613,  0.84002688,         nan,\n",
       "         0.84002688,         nan],\n",
       "       [ 1.79829315,  0.34021762,         nan,         nan, -0.14580755,\n",
       "        -0.63183273, -0.14580755, -0.63183273,  1.31226798, -1.60388308,\n",
       "         0.34021762, -0.63183273]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "from numpy.random import rand\n",
    "\n",
    "# X = np.array([[1,4,nan],[nan,5,6],[7,nan,8]])\n",
    "#X = df2\n",
    "\n",
    "X = np.array([[        nan,-0.85597905,-0.85597905,-0.85597905,0.19021757,1.75951249,0.19021757,-0.85597905,1.23641418,-0.33288074,1.23641418, -0.85597905],\n",
    "       [-0.88904338,         nan,1.60027808,         nan,-0.47415647,0.77050426,         nan,-1.30393029,0.35561735,-0.05926956,nan,nan],\n",
    "       [ 0.24152295,-0.72456884,         nan,-1.69066062,0.24152295,                nan,1.20761473,         nan,         nan,-0.72456884,1.20761473,  0.24152295],\n",
    "       [ 1.48841682,-0.3721042,1.95354707,0.55815631,         nan,                nan,-0.3721042,-0.3721042,-0.83723446,-0.83723446,-0.3721042, -0.83723446],\n",
    "       [        nan,-0.50401613,-1.84805914,         nan,0.84002688,0.84002688,-0.50401613,-0.50401613,0.84002688,         nan,0.84002688,         nan],\n",
    "       [ 1.79829315,0.34021762,         nan,         nan,-0.14580755,-0.63183273,-0.14580755,-0.63183273,1.31226798,-1.60388308,0.34021762, -0.63183273]])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-113-625f8d97d7d4>:28: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  S = np.cov(X[observed_rows, ].T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean matrix is : \n",
      " [ 0.66394607 -0.47965835  0.15831556 -0.7427598   0.13938389  0.65923325\n",
      "  0.24020017 -0.74400922  0.61003193 -0.7304436   0.71454014 -0.48827469]\n",
      "The covariance matrix is : \n",
      " [[ 0.82602533  0.28563198 -0.18183009  0.43998832  0.15332526 -0.35608767\n",
      "  -0.49158457  0.24729906 -0.0386651  -0.39015561 -0.36638831 -0.22288625]\n",
      " [ 0.28563198  0.16089844  0.05019233  0.10978531 -0.01954318 -0.25393454\n",
      "  -0.13581225  0.05647512  0.03590498 -0.17758555 -0.13905298 -0.05020494]\n",
      " [-0.18183009  0.05019233  1.7362611   0.23339364 -0.38239458 -0.26048318\n",
      "   0.23094866 -0.08193509 -0.67943187  0.08924067 -0.40026739  0.11227903]\n",
      " [ 0.43998831  0.10978532  0.23339362  0.49953686  0.07297129 -0.07416831\n",
      "  -0.39880948  0.15572711 -0.30260676 -0.11500508 -0.35594926 -0.23484387]\n",
      " [ 0.15332526 -0.01954318 -0.38239458  0.07297129  0.16061974  0.07977896\n",
      "  -0.14148809  0.08090816  0.01635423 -0.03547181  0.00431363 -0.05842104]\n",
      " [-0.35608767 -0.25393454 -0.26048318 -0.07416831  0.07977897  0.48926913\n",
      "   0.08037689 -0.05497876 -0.00630584  0.27248864  0.20758507 -0.0290964 ]\n",
      " [-0.49158457 -0.13581225  0.23094866 -0.39880946 -0.14148809  0.08037689\n",
      "   0.44949165 -0.15941707  0.05685233  0.16872974  0.23864193  0.25348232]\n",
      " [ 0.24729906  0.05647512 -0.08193509  0.15572711  0.08090816 -0.05497876\n",
      "  -0.15941707  0.08954426 -0.05657062 -0.09682873 -0.11327328 -0.07163418]\n",
      " [-0.0386651   0.03590498 -0.67943186 -0.30260676  0.01635423 -0.00630584\n",
      "   0.05685233 -0.05657062  0.51969384 -0.06690046  0.27575836  0.01925809]\n",
      " [-0.39015561 -0.17758555  0.08924067 -0.11500508 -0.03547181  0.27248864\n",
      "   0.16872974 -0.09682873 -0.06690046  0.23196233  0.14277583  0.05218088]\n",
      " [-0.36638831 -0.13905297 -0.40026739 -0.35594925  0.00431363  0.20758507\n",
      "   0.23864192 -0.11327328  0.27575836  0.14277583  0.32581262  0.1158104 ]\n",
      " [-0.22288626 -0.05020494  0.11227903 -0.23484387 -0.05842104 -0.0290964\n",
      "   0.25348231 -0.07163418  0.01925809  0.05218088  0.11581041  0.17335029]]\n"
     ]
    }
   ],
   "source": [
    "start = dt.now()\n",
    "result_imputed = impute_em(X)\n",
    "end = dt.now()\n",
    "\n",
    "result_imputed\n",
    "\n",
    "print('The mean matrix is : \\n',result_imputed['mu'])\n",
    "\n",
    "print('The covariance matrix is : \\n',result_imputed['Sigma'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
